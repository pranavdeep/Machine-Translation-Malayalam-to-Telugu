{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_Model_1.2.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18IamGzKdvNq","executionInfo":{"status":"ok","timestamp":1622853856409,"user_tz":-330,"elapsed":159044,"user":{"displayName":"Pranav Deep","photoUrl":"","userId":"03708664244266067618"}},"outputId":"e3363f08-68ec-47d2-ac94-36d90331582d"},"source":["!pip install OpenNMT-py -q"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 215kB 7.7MB/s \n","\u001b[K     |████████████████████████████████| 102kB 11.9MB/s \n","\u001b[K     |████████████████████████████████| 81kB 12.6MB/s \n","\u001b[K     |████████████████████████████████| 14.3MB 197kB/s \n","\u001b[K     |████████████████████████████████| 81kB 11.6MB/s \n","\u001b[K     |████████████████████████████████| 645kB 49.2MB/s \n","\u001b[K     |████████████████████████████████| 748.8MB 15kB/s \n","\u001b[K     |████████████████████████████████| 61kB 10.4MB/s \n","\u001b[K     |████████████████████████████████| 1.2MB 48.1MB/s \n","\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9fFnmArinmr6","executionInfo":{"status":"ok","timestamp":1622853943948,"user_tz":-330,"elapsed":343,"user":{"displayName":"Pranav Deep","photoUrl":"","userId":"03708664244266067618"}},"outputId":"fdde9435-517a-4801-e571-98fb651c505b"},"source":["ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oP8B1jfCnnOB","executionInfo":{"status":"ok","timestamp":1622853884654,"user_tz":-330,"elapsed":28257,"user":{"displayName":"Pranav Deep","photoUrl":"","userId":"03708664244266067618"}},"outputId":"557efb38-46c7-4938-f227-0bfd4f098ea9"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X_AY1cg5d8vN","executionInfo":{"status":"ok","timestamp":1622854198202,"user_tz":-330,"elapsed":358,"user":{"displayName":"Pranav Deep","photoUrl":"","userId":"03708664244266067618"}},"outputId":"2b9188dd-1ce6-425c-a80f-0b2d44e68809"},"source":["cd /content/drive/MyDrive/Dataset_Prepared_ONMT_Format"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Dataset_Prepared_ONMT_Format\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uhFcQLCgfz7w","executionInfo":{"status":"ok","timestamp":1622854200281,"user_tz":-330,"elapsed":490,"user":{"displayName":"Pranav Deep","photoUrl":"","userId":"03708664244266067618"}},"outputId":"06dd5140-1af2-4e47-c633-8f123209358a"},"source":["ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mallu.vocab   transformer.yaml  X_train.txt  Y_test.txt   Y_val.txt\n","telugu.vocab  X_test.txt        X_val.txt    Y_train.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v8K_5b9SzUhG","executionInfo":{"status":"ok","timestamp":1622854202619,"user_tz":-330,"elapsed":370,"user":{"displayName":"Pranav Deep","photoUrl":"","userId":"03708664244266067618"}},"outputId":"7471d87e-0a7b-4392-8b61-b97e39b9dc28"},"source":["!nvidia-smi -L"],"execution_count":null,"outputs":[{"output_type":"stream","text":["GPU 0: Tesla T4 (UUID: GPU-557d151a-24a9-a5eb-2858-f2f49babfc8e)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mioBuY8if2ej","outputId":"d241f361-cc9f-4226-a265-a517626c580c"},"source":["!onmt_train -config transformer.yaml"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2021-06-05 00:50:05,002 INFO] Missing transforms field for corpus_1 data, set to default: [].\n","[2021-06-05 00:50:05,003 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n","[2021-06-05 00:50:05,003 INFO] Missing transforms field for valid data, set to default: [].\n","[2021-06-05 00:50:05,003 INFO] Parsed 2 corpora from -data.\n","[2021-06-05 00:50:05,003 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.\n","[2021-06-05 00:50:05,004 INFO] Loading vocab from text file...\n","[2021-06-05 00:50:05,004 INFO] Loading src vocabulary from ./mallu.vocab\n","[2021-06-05 00:50:05,136 INFO] Loaded src vocab has 52695 tokens.\n","[2021-06-05 00:50:05,156 INFO] Loading tgt vocabulary from ./telugu.vocab\n","[2021-06-05 00:50:05,278 INFO] Loaded tgt vocab has 49204 tokens.\n","[2021-06-05 00:50:05,295 INFO] Building fields with vocab in counters...\n","[2021-06-05 00:50:05,364 INFO]  * tgt vocab size: 43962.\n","[2021-06-05 00:50:05,440 INFO]  * src vocab size: 48087.\n","[2021-06-05 00:50:05,441 INFO]  * src vocab size = 48087\n","[2021-06-05 00:50:05,441 INFO]  * tgt vocab size = 43962\n","[2021-06-05 00:50:05,443 INFO] Building model...\n","[2021-06-05 00:50:10,244 INFO] NMTModel(\n","  (encoder): TransformerEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(48087, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","    )\n","    (transformer): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(43962, 512, padding_idx=1)\n","        )\n","        (pe): PositionalEncoding(\n","          (dropout): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","    (transformer_layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (feed_forward): PositionwiseFeedForward(\n","          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n","          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n","          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","          (dropout_1): Dropout(p=0.2, inplace=False)\n","          (dropout_2): Dropout(p=0.2, inplace=False)\n","        )\n","        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        (drop): Dropout(p=0.2, inplace=False)\n","        (context_attn): MultiHeadedAttention(\n","          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n","          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n","          (softmax): Softmax(dim=-1)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=512, out_features=43962, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax(dim=-1)\n","  )\n",")\n","[2021-06-05 00:50:10,256 INFO] encoder: 43535872\n","[2021-06-05 00:50:10,256 INFO] decoder: 70286266\n","[2021-06-05 00:50:10,256 INFO] * number of parameters: 113822138\n","[2021-06-05 00:50:10,261 INFO] Starting training on GPU: [0]\n","[2021-06-05 00:50:10,262 INFO] Start training loop and validate every 100 steps...\n","[2021-06-05 00:50:10,262 INFO] corpus_1's transforms: TransformPipe()\n","[2021-06-05 00:50:10,264 INFO] Loading ParallelCorpus(./X_train.txt, ./Y_train.txt, align=None)...\n","[2021-06-05 00:50:48,633 INFO] Loading ParallelCorpus(./X_train.txt, ./Y_train.txt, align=None)...\n","[2021-06-05 00:51:30,089 INFO] Loading ParallelCorpus(./X_train.txt, ./Y_train.txt, align=None)...\n","[2021-06-05 00:52:10,763 INFO] Loading ParallelCorpus(./X_train.txt, ./Y_train.txt, align=None)...\n","[2021-06-05 00:53:04,841 INFO] Loading ParallelCorpus(./X_train.txt, ./Y_train.txt, align=None)...\n","[2021-06-05 00:53:49,186 INFO] Loading ParallelCorpus(./X_train.txt, ./Y_train.txt, align=None)...\n","[2021-06-05 00:54:23,133 INFO] valid's transforms: TransformPipe()\n","[2021-06-05 00:54:23,135 INFO] Loading ParallelCorpus(./X_val.txt, ./Y_val.txt, align=None)...\n","[2021-06-05 00:54:24,011 WARNING] The batch will be filled until we reach 1,its size may exceed 32 tokens\n","[2021-06-05 00:54:24,014 WARNING] The batch will be filled until we reach 1,its size may exceed 32 tokens\n","[2021-06-05 00:54:24,015 WARNING] The batch will be filled until we reach 1,its size may exceed 32 tokens\n","[2021-06-05 00:54:24,015 WARNING] The batch will be filled until we reach 1,its size may exceed 32 tokens\n","[2021-06-05 00:54:24,017 WARNING] The batch will be filled until we reach 1,its size may exceed 32 tokens\n","[2021-06-05 00:54:44,593 INFO] Validation perplexity: 3016.19\n","[2021-06-05 00:54:44,593 INFO] Validation accuracy: 17.5293\n","[2021-06-05 00:54:52,295 INFO] Loading ParallelCorpus(./X_train.txt, ./Y_train.txt, align=None)...\n","[2021-06-05 00:55:33,937 INFO] Loading ParallelCorpus(./X_train.txt, ./Y_train.txt, align=None)...\n","[2021-06-05 00:56:28,903 INFO] Loading ParallelCorpus(./X_train.txt, ./Y_train.txt, align=None)...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i4ujE3eUgVah"},"source":[""],"execution_count":null,"outputs":[]}]}